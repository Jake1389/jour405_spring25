---
title: "HW11: Education Level and Survey Weighting"
author: "Jake Kauderer"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(kableExtra)
```

# Introduction

In this assignment, you'll examine how survey weighting affects our understanding of voting intentions across different education levels, using the data we examined in class. You'll calculate both weighted and unweighted statistics, create visualizations, and reflect on the implications for reporting.

## The Data

The nonvoters dataset contains survey responses about voting intentions and behaviors from a national survey. The survey was conducted prior to an election and includes demographic information like education level.

```{r}
# Load the dataset
nonvoters_data <- read_csv("https://raw.githubusercontent.com/dwillis/jour405_files/refs/heads/main/nonvoters_data.csv")

# Take a quick look at the data structure
glimpse(nonvoters_data)
```

### Key Variables

- `weight`: Survey weight assigned to each respondent
- `Q21`: Voting intention (1 = Yes, 2 = No, 3 = Unsure/Undecided)
- `educ`: Education level (College, Some college, High school or less)

## Task 1: Education Distribution

First, let's examine the distribution of education levels in our sample. Replace "REPLACE_ME" with the correct variable for education level.

```{r}

education_distribution <- nonvoters_data |>
  count(educ) |>
  mutate(percentage = n / sum(n) * 100) |>
  kable(digits = 1, col.names = c("Education Level", "Count", "Percentage (%)"))

education_distribution
```

## Task 2: Reflection Question

Why might education levels in survey samples often differ from the general population? What factors might cause certain education groups to be over or underrepresented?

This is because the less-educated people are likely harder to reach. This could be because they don't care as much about whatever sample is going on (may not affect them as much) or maybe they're just physically harder to reach out to. Sample methods can cause certain education groups to be over or underrepresented — think of reaching out by phone and not reaching enough of the less-educated people since they may be less likely to have phones. Also, like I talked about it earlier in this reflection, there's the likely factor of higher-educated people being more likely to respond. Even something like literacy barriers could play a role — in areas with high poverty rates less-educated people may not even have the opportunity to learn English well. The area itself matters too, certain ones will obviously have more highly-educated people, proving the importance of weighting. 


## Task 3: Unweighted Analysis by Education

Now, let's calculate unweighted voting intentions by education level. This is what we would report if we didn't apply any weighting to our sample.

```{r}
# Calculate unweighted voting intentions by education
unweighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Count responses
  summarize(count = n(), .groups = "drop_last") |>
  # Calculate percentages
  mutate(total = sum(count),
         percentage = count / total * 100) |>
  ungroup()

# Create a more readable format with voting intentions as columns
unweighted_educ_summary <- unweighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(unweighted_educ_summary, digits = 1, caption = "Unweighted Voting Intentions by Education Level")
```

## Task 4: Reflection Question

Based just on this unweighted analysis, what headline might you write for a news story about education and voting intentions?

People with a high school education are much less are much less likely to vote in elections.

## Task 5: Weighted Analysis by Education

Next, let's apply survey weights to see how this changes our results. Instead of just counting responses, we'll sum the weights for each group. Replace "REPLACE_ME" with the appropriate weight variable

```{r weighted-by-education}

weighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Sum the weights instead of counting
  summarize(weighted_count = sum(weight), .groups = "drop_last") |>
  # Calculate weighted percentages
  mutate(weighted_total = sum(weighted_count),
         weighted_percentage = weighted_count / weighted_total * 100) |>
  ungroup()

# Create a more readable format
weighted_educ_summary <- weighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = weighted_percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(weighted_educ_summary, digits = 1, caption = "Weighted Voting Intentions by Education Level")
```

## Task 6: Reflection Questions

1. How did the percentages change after applying weights? Which education group showed the biggest changes?

The "college" and "some college" groups changed minimally, while the "high school or less" group had a big drop in "yes" and rise in "no" and "unsure." This helps demonstrate the point that these groups are much less likely to vote. 

2. Why might the weighted results be considered more accurate than the unweighted results?

This is because it factors in the reality that not all gorups are survyed exactly equally — talked about it before but depending on the area, survey methods and such there can be a different amount of people per group surveyed. Weighting is a smart, albeit not perfect way to help make up for disparities by factoring in some people's votes more than others. 

## Task 7: Comparison of Weighted vs. Unweighted Results

Let's create a direct comparison table to see the differences more clearly.

```{r}

comparison <- unweighted_educ_summary |>
  inner_join(weighted_educ_summary, by = "educ", suffix = c("_unweighted", "_weighted")) |>
  mutate(
    # Calculate the differences between weighted and unweighted percentages
    yes_diff = `Yes (%)_weighted` - `Yes (%)_unweighted`,
    no_diff = `No (%)_weighted` - `No (%)_unweighted`,
    unsure_diff = `Unsure (%)_weighted` - `Unsure (%)_unweighted`
  ) |>
  # Select just the columns we want to display
  select(educ, yes_diff, no_diff, unsure_diff) |>
  rename(
    "Education Level" = educ,
    "Yes (% point diff)" = yes_diff,
    "No (% point diff)" = no_diff,
    "Unsure (% point diff)" = unsure_diff
  )

kable(comparison, digits = 1, caption = "Difference Between Weighted and Unweighted Results (percentage points)")
```

## Task 8: Reflection Question

Which education group shows the largest differences between weighted and unweighted results?

The "high school or less" group shows the largest differences between weighted and unweighted results.

## Task 9: Visualization

Visualizations can help us see the differences more clearly. Let's create a bar chart comparing weighted and unweighted "Yes" responses by education level. Replace "REPLACE_ME" with the correct variable name

```{r}
educ_viz_data <- bind_rows(
  # Unweighted data
  unweighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses (Q21=1)
    mutate(Type = "Unweighted") |>
    select(Type, educ, percentage),
  
  # Weighted data - 
  weighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses
    mutate(
      Type = "Weighted",
      percentage = weighted_percentage
    ) |>
    select(Type, educ, percentage)
)

# Create a grouped bar chart
ggplot(educ_viz_data, 
       aes(x = educ, y = percentage, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), 
            position = position_dodge(width = 0.9), vjust = -0.5) +
  labs(
    title = "Weighted vs. Unweighted 'Yes' Responses by Education",
    subtitle = "Q21: Do you plan to vote in the November election?",
    y = "Percentage (%)",
    x = "Education Level"
  ) +
  scale_fill_manual(values = c("Unweighted" = "#619CFF", "Weighted" = "#F8766D")) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )
```

## Task 10: Reflection Questions

Does the visualization make it easier to see the differences between weighted and unweighted results? Why or why not?

It does, I'm also a pretty visual learner so it helps. It shows how minimal "the college" and "some college" group are unchanged, while illustrating the larger shift with the "high school or less" group. I wouldn't say the visualization is anything groundbreaking, but it does help convey the broad point that the "high school or less" group has the largest change between weighted and unweighted results.

## Task 11: Summary

Based on your analysis of weighted and unweighted results by education level, write a brief (2-3 paragraph) journalistic summary of what you found. You should try to address:

1. How education level relates to voting intentions
2. How weighting affected your understanding of this relationship
3. What this means for interpreting polling results in news reporting

  Higher educated people are more likely to vote, according to data from a survey asking whether people would vote in the November election. Those who attended college said they would vote at about a 20 percent higher rate than those who did not. The data was weighted as to best demonstrate all of the respective groups' views, though the "college" and "some college" group saw minimal change. However, the "high school or less" group dropped by about three percent when weighted, further proving how they're the least likely to vote. 
  Weighting can sometimes show that unweighted data may not tell the whole story — in this case it corroborates the unweighted evidence, though. In news reporting, using weighted data is generally a good idea, though it has to be specified exactly how the weighting is done. If weighting isn't used, certain demographics can be overrepresented, potentially leading to misleading conclusions. Regardless of the approach, reporters should be transparent and be careful when comparing polls — looking at methodology is key. 

## Task 12: Final Reflection Questions

1. Why is it important for journalists to understand survey weighting when reporting on polls?
This is because polls can tell different stories based on the methodology, using either weighted or unweighted data. If a journalist is comparing polls they must gauge exactly how the poll was created. If they don't take the time to understand weighting, they could misinform people. Weighted data is generally more accurate because it accounts for these disparities that inevitably arise when doing a survey — a person can't find an equal amount of people for each group in all likelihood. If a reporter was working on a story with unweighted results, they should caution the readers of that.

2. How might the differences between weighted and unweighted results affect how you would report on this data?
The differences are key. Think of if you got a poll with purely unweighted data, certain demographics can be over represented in an imbalanced sample. For this story, the unweighted and weighted data were similar, but that isn't always the case.

3. What additional information would you want to know about how the weights were calculated before using this data in a news story?
I would want to know the specifics behind the weighting. What exactly did the pollsters adjust for and why? Equally important is how large the weighting is — was it done in abundance to make up for a lack of a certain group being surveyed, or was it just a little? Finally, margin of error would be important to note, ideally for both weighted and unweighted.
